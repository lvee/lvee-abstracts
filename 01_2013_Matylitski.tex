\documentclass[10pt, a5paper]{article}
\input{preamble.tex}

\begin{document}

\title{Flexible user"=level implementation of SLAB"=like free list}%\footnote{Текст данных и последующих тезисов, кроме специально оговоренных случаев, доступен под лицензией Creative Commons Attribution-ShareAlike 3.0}

\author{Ivan Matylitski\footnote{Minsk, Belarus; \url{buffovich@gmail.com}}}
\maketitle

\begin{abstract}
A project implementing SLAB"=like objects free list is presented,   targeted to be used in user"=space code. The differences from another similar projects are flexibility and orientation to \linebreak configuration features used at compilation and run"=time stages. Code is written in pure C (C11) and allows end user to build library for embedded/low"=power systems as well as for using in high"=load server systems.
\end{abstract}

\subsection*{Introduction}

Term <<SLAB>> and the mechanism was initially introduced by Jeff Bonwick in Solaris 2.4 kernel. For now, identical approach has been adopted at vast majority of Unix"=like OSes kernels as well as at some not Unix"=like systems. SLAB became the state of art in kernel"=level object management because of noticeable effectiveness.

Synonym of word <<slab>> is <<chunk>>. This word is partially self"=descriptive because it reflects how operations are performed inside SLAB structure.

The idea of slab"=list (or just <<slab>>) is very close to the idea of free"=list (or object pool). Free"=lists are known to be used as a replacement of allocation"=initialization"=finalization"=deallocation (AIFD) cycle for \linebreak frequently used objects. An object can be placed into a special list of unused instances of particular class just after it is not needed anymore for future re"=using.

SLAB works similarly to free"=list. The main architectural difference is that SLAB is more self"=contained and autonomous.

Firstly, SLAB represents object construction by itself according to parameters specified by user during SLAB"=list initialization. Instance construction performs under the hood according to current needs (i.e. if no unused instanced have been found in internal lists).

Secondly, allocation and construction phases act under set of \linebreak instances. It means that if no unused instances are available then logic will allocate several objects (number depends on particular policy \linebreak embedded into the logic) at one fell swoop and will initialize them all at once. That's where, probably, <<slab>> came from.

Thirdly, internal lists are lists of packages or magazines, which contain particular amount of class instances in array. In advance, all internal memory allocation"=deallocation operations use mentioned \linebreak packages as atomic unit.

And, finally, SLAB contains three lists:

\begin{itemize}
  \item free list "--- list of packages which don't contain any currently used instance;
  \item partial list "--- list of packages which contain both kinds of instances (used and unused ones);
  \item full list "--- list of packages which contain only used objects and which are not available for further allocation.
\end{itemize}

\subsection*{About the project}

The main goal of presented project is to provide user"=space code with the same functionality, which has been available for kernel code.

Code is distributed under  BSD license and published on GitHub:

\begin{itemize}
  \item \url{https://github.com/buffovich/libreclaim} "--- safe memory \linebreak reclamation facility
\end{itemize}

\begin{itemize}
  \item \url{https://github.com/buffovich/libmempool} "--- SLAB itself
\end{itemize}

Implementation provides ability to choose:

\begin{itemize}
  \item particular back"=end for memory allocation at compilation stage (ptmalloc, je\_malloc, tcmalloc is currently available);
  \item particular scheme of behavior in multi"=threaded environment at run"=time:
  \begin{itemize}
    \item local lists for each thread;
    \item global, per"=SLAB lists;
  \end{itemize}
  \item scheme of protecting of lists from corruption under multi"=threaded contention at run"=time:
  \begin{itemize}
   \item simple thread"=unaware scheme;
   \item coarse"=grained locks for three lists;
   \item fine"=grained locks;
   \item lock"=less scheme.
  \end{itemize}
  \item optional cache"=coloring
\end{itemize}

\subsection*{Use cases}

As you may notice, mentioned SLAB implementation can be adopted for wide range of use cases. For example, if user needs scalable and fast solution with keeping in mind that objects won't be transmitted to or shared with another threads then combination <<per"=thread list/thread"=unaware>> can be employed. If user needs the same level of scalability and thread"=safety with keeping in mind that object exchanges are \linebreak relatively rare then thread"=unaware lists can be replaced with coarse"=grained locked lists. In case of crucial scalability and frequent exchanges user can employ lock"=less scheme or fine"=grained locks.

Let's consider all available options separately with their advantages and drawbacks:

\begin{itemize}
  \item cache coloring:\begin{itemize}
  \item \textbf{introduce cache"=awareness into SLAB and higher \linebreak performance as a result};
  \item \emph{requires extra memory (do not suit for embedded solutions)};
\end{itemize}
  \item per"=thread lists:\begin{itemize}
  \item \textbf{play on local memory for thread and higher speed of memory access as a result};
  \item \emph{extra memory is needed (do not suit for devices with limited memory)};
  \item \emph{particular thread cannot reuse objects freed by another thread (if threads created and terminated frequently and cost of object initialization is high then it will provide undesirable overhead)};
  \item \emph{for single"=core devices has no sense};
\end{itemize}
  \item per"=SLAB lists:\begin{itemize}
  \item \textbf{low"=memory footprint (good for embedded devices)};
  \item \emph{unawareness about thread"=local memory (higher costs of \linebreak memory access for SMP systems)};
\end{itemize}
 \item simple thread"=unaware scheme:\begin{itemize}
  \item \textbf{fast and simple};
  \item \emph{not applicable in condition of concurrent access};
\end{itemize}
  \item coarse"=grained locks for three lists:\begin{itemize}
  \item \textbf{safe in multi"=threaded environment;}
  \item \textbf{simple and effective in sense of wasted CPU power and very fast under low or zero contention;}
  \item \emph{slow and enforce extra re"=scheduling under high contention;}
  \item \emph{overall system progress isn't guaranteed;}
\end{itemize}
  \item fine"=grained locks:\begin{itemize}
  \item \textbf{safe in multi"=threaded environment;}
  \item \textbf{outperforms coarse"=grained lock under high \linebreak contention;}
  \item \emph{increased memory and locking overhead because of issuing extra memory barriers (do not suit for cases with low level of contention)}
  \item \emph{overall system progress isn't guaranteed;}
\end{itemize}
  \item lock"=less scheme:\begin{itemize}
  \item \textbf{do not use locking under the hood (guarantee of system"=wide progress, so it suits for realtime systems)}
  \item \textbf{re"=scheduling is eliminated by design (sometimes can outperforms all lock"=based schemes under very high contention on limited amount of cores, so it suits for some high"=loaded and embedded systems)}
  \item \emph{much more complex solution which can't consume CPU cycles more effectively (don't suit for low"=power devices)}
  \item \emph{not effective under low contention}
\end{itemize}
\end{itemize}

Let's consider available allocation backends and its use cases:

\begin{itemize}
  \item ptmalloc (standard libc6 allocator):\begin{itemize}
  \item \textbf{has intermediate parameters (suits for all use cases);}
  \item \emph{lock"=based heap}
\end{itemize}
  \item je\_malloc:\begin{itemize}
  \item \textbf{relatively scalable because of using thread"=local \linebreak arenas for allocation;}
  \item \textbf{has lower memory footprint in comparing with other scalable allocators;}
\end{itemize}
  \item tcmalloc:\begin{itemize}
  \item \textbf{very scalable and fast;}
  \item \emph{noticeable amount of ancillary memory allocated just for \linebreak internal usage;}
\end{itemize}
\end{itemize}

\subsection*{Lock"=less lists}

It's worth considering lock"=less lists implementation separately. One of solved problems was safe memory reclamation. Scheme offered by Gidenstam, Papatriantafilou, Sundell, Tsigas \cite{Matyl1} is used for this purpose and it has its own sub"=project libreclaim. This is an aggregate of two methods:

\begin{itemize}
  \item hazard pointers (M. Michael \cite{Matyl2});
  \item reference counting.
\end{itemize}

Deleted instances list and hazard pointers list are defined for each participating thread. These lists are available for each thread for reading.

Method was modified and simplified in some particular parts:

Original method requires deletion list and hazard list being available for each participating thread. Mentioned lists were integrated into per"=thread structure. All structures are linked into double"=linked list. Each thread set address of its structure in thread"=specific data.

Double"=linked list of thread structures is managed with help of RCU reclamation method. Writers are not block readers. But modification is exclusive. For tracking readers, thread structure has special numerical tag which is obtained from common counter. Counter is incremented by each thread with fetch"=and"=add primitive. Writing procedure is \linebreak performed in context of thread creation and termination. Reading is performed each time thread needs to clean its deletion list. Writers can be readers as well during thread structure reclamation (during thread termination) so they are taken in account in common writers counter.

Lock"=free double"=linked list structure which is used in lock"=less SLAB is constructed according to Sundell and Tsigas \cite{Matyl3}. They offered scheme where prev pointer plays auxiliary role. Hence we can employ single"=word compare"=and"=swap for atomic insert/delete. One of the \linebreak modifications of original algorithm is that deletion phase has two kinds:

\begin{itemize}
  \item moving into another list;
  \item actual deletion and reclamation.
\end{itemize}

Moreover, actual deletion can be canceled if someone allocated object from chunk which is under reclamation. Also, all pointers are tagged according to the list they are supposed to be.

\begin{thebibliography}{9}

\bibitem{Matyl1} Anders Gidenstam, Marina Papatriantafilou, Hakan Sundell, Phillipas Tsigas. Efficient and Reliable Lock"=Free Memory Reclamation Based on Reference Counting. IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
\bibitem{Matyl2} Maged M. Michael. Safe Memory Reclamation for Dynamic Lock"=Free Objects Using Atomic Reads and Writes. IBM Thomas J. Watson Research Center P.O. Box 218 Yorktown Heights NY 10598
\bibitem{Matyl3} Hakan Sundell, Phillipas Tsigas. Lock"=free deques and doubly linked lists. J. Parallel Distrib. Comput. 68 (2008) 1008–1020
\end{thebibliography}

\end{document}




